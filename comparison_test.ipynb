{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nprobust: Python vs R Comparison\n",
    "\n",
    "This notebook tests the Python implementation of the nprobust package and compares results with R.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run this notebook to generate Python results\n",
    "2. Run the companion R script `comparison_test.R` to generate R results\n",
    "3. Compare the outputs side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nprobust package loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from nprobust import lprobust, lpbwselect, kdrobust, kdbwselect\n",
    "\n",
    "print(\"nprobust package loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Data\n",
    "\n",
    "We use the same random seed as R to ensure identical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 observations\n",
      "x range: [0.0002, 0.9966]\n",
      "y range: [-2.0313, 2.4828]\n",
      "\n",
      "First 5 observations:\n",
      "          x         y\n",
      "0  0.914806 -1.058168\n",
      "1  0.937075 -0.360622\n",
      "2  0.286140  0.375082\n",
      "3  0.830448 -0.779939\n",
      "4  0.641746 -0.128605\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility (same as R)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "df = pd.read_csv('test_data_r.csv')\n",
    "x = df.x.values\n",
    "y = df.y.values\n",
    "\n",
    "print(f\"Generated {n} observations\")\n",
    "print(f\"x range: [{x.min():.4f}, {x.max():.4f}]\")\n",
    "print(f\"y range: [{y.min():.4f}, {y.max():.4f}]\")\n",
    "print(f\"\\nFirst 5 observations:\")\n",
    "print(pd.DataFrame({'x': x[:5], 'y': y[:5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 1: lprobust with Fixed Bandwidth\n",
    "\n",
    "Local polynomial regression with h=0.15, p=1, Epanechnikov kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: lprobust(y, x, eval=c(0.1,0.25,0.5,0.75,0.9), h=0.15, p=1)\n",
      "======================================================================\n",
      "Call: lprobust\n",
      "\n",
      "Sample size (n)                              =    500\n",
      "Polynomial order for point estimation (p)    =    1\n",
      "Order of derivative estimated (deriv)        =    0\n",
      "Polynomial order for confidence interval (q) =    2\n",
      "Kernel function                              =    Epanechnikov\n",
      "Bandwidth method                             =    Manual\n",
      "\n",
      "=============================================================================\n",
      "                                     Point      Std.       Robust B.C.       \n",
      "          eval         h   Eff.n      Est.     Error      [ 95% C.I. ]       \n",
      "=============================================================================\n",
      "   1     0.100     0.150     132     0.547     0.041[  0.463 ,   0.677]\n",
      "   2     0.250     0.150     154     0.889     0.051[  0.760 ,   1.103]\n",
      "   3     0.500     0.150     152    -0.062     0.043[ -0.210 ,   0.040]\n",
      "   4     0.750     0.150     130    -0.967     0.039[ -1.137 ,  -0.918]\n",
      "   5     0.900     0.150     122    -0.572     0.054[ -0.768 ,  -0.457]\n",
      "-----------------------------------------------------------------------------\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation points (same as R)\n",
    "eval_points = np.array([0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "\n",
    "# Run lprobust\n",
    "result_lp = lprobust(y, x, eval=eval_points, h=0.15, p=1, kernel=\"epa\", vce=\"nn\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 1: lprobust(y, x, eval=c(0.1,0.25,0.5,0.75,0.9), h=0.15, p=1)\")\n",
    "print(\"=\"*70)\n",
    "result_lp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display raw estimates for easy comparison\n",
    "print(\"\\nRaw Estimates (for comparison with R):\")\n",
    "columns = ['eval', 'h', 'b', 'N', 'tau.us', 'tau.bc', 'se.us', 'se.rb']\n",
    "df_lp = pd.DataFrame(result_lp.Estimate, columns=columns)\n",
    "print(df_lp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 2: lprobust with Different Kernel (Uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lp_uni = lprobust(y, x, eval=eval_points, h=0.15, p=1, kernel=\"uni\", vce=\"nn\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 2: lprobust with Uniform kernel\")\n",
    "print(\"=\"*70)\n",
    "result_lp_uni.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 3: lprobust with Triangular Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lp_tri = lprobust(y, x, eval=eval_points, h=0.15, p=1, kernel=\"tri\", vce=\"nn\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 3: lprobust with Triangular kernel\")\n",
    "print(\"=\"*70)\n",
    "result_lp_tri.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 4: lprobust with Higher Polynomial Order (p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lp_p2 = lprobust(y, x, eval=eval_points, h=0.15, p=2, kernel=\"epa\", vce=\"nn\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 4: lprobust with p=2\")\n",
    "print(\"=\"*70)\n",
    "result_lp_p2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 5: lprobust Derivative Estimation (deriv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lp_d1 = lprobust(y, x, eval=eval_points, h=0.15, p=2, deriv=1, kernel=\"epa\", vce=\"nn\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 5: lprobust with deriv=1 (first derivative)\")\n",
    "print(\"=\"*70)\n",
    "result_lp_d1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 6: lpbwselect - MSE-DPI Bandwidth Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_mse = lpbwselect(y, x, eval=eval_points, bwselect=\"mse-dpi\", p=1, kernel=\"epa\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 6: lpbwselect with MSE-DPI\")\n",
    "print(\"=\"*70)\n",
    "bw_mse.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRaw Bandwidths (for comparison with R):\")\n",
    "df_bw = pd.DataFrame(bw_mse.bws, columns=['eval', 'h', 'b'])\n",
    "print(df_bw.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 7: lpbwselect - IMSE-DPI Bandwidth Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_imse = lpbwselect(y, x, bwselect=\"imse-dpi\", p=1, kernel=\"epa\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 7: lpbwselect with IMSE-DPI\")\n",
    "print(\"=\"*70)\n",
    "bw_imse.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 8: lprobust with Automatic Bandwidth Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lp_auto = lprobust(y, x, eval=eval_points, p=1, kernel=\"epa\", bwselect=\"mse-dpi\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 8: lprobust with automatic bandwidth (MSE-DPI)\")\n",
    "print(\"=\"*70)\n",
    "result_lp_auto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 9: kdrobust - Kernel Density Estimation with Fixed Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation points for density\n",
    "eval_kd = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "result_kd = kdrobust(x, eval=eval_kd, h=0.1, kernel=\"epa\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 9: kdrobust(x, eval=c(0.1,0.3,0.5,0.7,0.9), h=0.1)\")\n",
    "print(\"=\"*70)\n",
    "result_kd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRaw Estimates (for comparison with R):\")\n",
    "df_kd = pd.DataFrame(result_kd.Estimate, columns=['eval', 'h', 'b', 'N', 'f.us', 'f.bc', 'se.us', 'se.rb'])\n",
    "print(df_kd.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 10: kdrobust with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_kd_gau = kdrobust(x, eval=eval_kd, h=0.1, kernel=\"gau\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 10: kdrobust with Gaussian kernel\")\n",
    "print(\"=\"*70)\n",
    "result_kd_gau.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 11: kdbwselect - Bandwidth Selection for KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_kd = kdbwselect(x, eval=eval_kd, bwselect=\"mse-dpi\", kernel=\"epa\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 11: kdbwselect with MSE-DPI\")\n",
    "print(\"=\"*70)\n",
    "bw_kd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 12: kdrobust with Automatic Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_kd_auto = kdrobust(x, eval=eval_kd, kernel=\"epa\", bwselect=\"mse-dpi\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 12: kdrobust with automatic bandwidth (MSE-DPI)\")\n",
    "print(\"=\"*70)\n",
    "result_kd_auto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 13: lprobust with HC Variance Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with HC0\n",
    "result_hc0 = lprobust(y, x, eval=eval_points, h=0.15, p=1, kernel=\"epa\", vce=\"hc0\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 13a: lprobust with vce='hc0'\")\n",
    "print(\"=\"*70)\n",
    "result_hc0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with HC1\n",
    "result_hc1 = lprobust(y, x, eval=eval_points, h=0.15, p=1, kernel=\"epa\", vce=\"hc1\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 13b: lprobust with vce='hc1'\")\n",
    "print(\"=\"*70)\n",
    "result_hc1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with HC2\n",
    "result_hc2 = lprobust(y, x, eval=eval_points, h=0.15, p=1, kernel=\"epa\", vce=\"hc2\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 13c: lprobust with vce='hc2'\")\n",
    "print(\"=\"*70)\n",
    "result_hc2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Table for Easy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF KEY RESULTS FOR R COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. lprobust (h=0.15, p=1, epa, vce=nn):\")\n",
    "print(pd.DataFrame(result_lp.Estimate, columns=['eval', 'h', 'b', 'N', 'tau.us', 'tau.bc', 'se.us', 'se.rb']).round(6).to_string(index=False))\n",
    "\n",
    "print(\"\\n2. lpbwselect (mse-dpi):\")\n",
    "print(pd.DataFrame(bw_mse.bws, columns=['eval', 'h', 'b']).round(6).to_string(index=False))\n",
    "\n",
    "print(\"\\n3. kdrobust (h=0.1, epa):\")\n",
    "print(pd.DataFrame(result_kd.Estimate, columns=['eval', 'h', 'b', 'N', 'f.us', 'f.bc', 'se.us', 'se.rb']).round(6).to_string(index=False))\n",
    "\n",
    "print(\"\\n4. kdbwselect (mse-dpi):\")\n",
    "print(pd.DataFrame(bw_kd.bws, columns=['eval', 'h', 'b']).round(6).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Local polynomial regression\n",
    "    ax1 = axes[0]\n",
    "    ax1.scatter(x, y, alpha=0.3, s=10, label='Data')\n",
    "    \n",
    "    # Get more evaluation points for smooth curve\n",
    "    eval_smooth = np.linspace(0.05, 0.95, 50)\n",
    "    result_smooth = lprobust(y, x, eval=eval_smooth, h=0.15, p=1, kernel=\"epa\")\n",
    "    \n",
    "    ax1.plot(result_smooth.Estimate[:, 0], result_smooth.Estimate[:, 4], 'b-', linewidth=2, label='LP Estimate')\n",
    "    ax1.fill_between(result_smooth.Estimate[:, 0], \n",
    "                     result_smooth.Estimate[:, 5] - 1.96*result_smooth.Estimate[:, 7],\n",
    "                     result_smooth.Estimate[:, 5] + 1.96*result_smooth.Estimate[:, 7],\n",
    "                     alpha=0.2, color='blue', label='95% CI')\n",
    "    \n",
    "    # True function\n",
    "    x_true = np.linspace(0, 1, 100)\n",
    "    ax1.plot(x_true, np.sin(2*np.pi*x_true), 'r--', linewidth=1.5, label='True function')\n",
    "    \n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_title('Local Polynomial Regression (p=1, h=0.15)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Kernel density estimation\n",
    "    ax2 = axes[1]\n",
    "    ax2.hist(x, bins=30, density=True, alpha=0.3, label='Histogram')\n",
    "    \n",
    "    eval_kd_smooth = np.linspace(0.05, 0.95, 50)\n",
    "    result_kd_smooth = kdrobust(x, eval=eval_kd_smooth, h=0.1, kernel=\"epa\")\n",
    "    \n",
    "    ax2.plot(result_kd_smooth.Estimate[:, 0], result_kd_smooth.Estimate[:, 4], 'b-', linewidth=2, label='KDE Estimate')\n",
    "    ax2.fill_between(result_kd_smooth.Estimate[:, 0],\n",
    "                     result_kd_smooth.Estimate[:, 5] - 1.96*result_kd_smooth.Estimate[:, 7],\n",
    "                     result_kd_smooth.Estimate[:, 5] + 1.96*result_kd_smooth.Estimate[:, 7],\n",
    "                     alpha=0.2, color='blue', label='95% CI')\n",
    "    \n",
    "    # True density (uniform)\n",
    "    ax2.axhline(y=1, color='r', linestyle='--', linewidth=1.5, label='True density')\n",
    "    \n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_title('Kernel Density Estimation (h=0.1)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('nprobust_python_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nPlot saved to nprobust_python_results.png\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"matplotlib not installed. Skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Results for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Python results to CSV files for detailed comparison\n",
    "pd.DataFrame(result_lp.Estimate, \n",
    "             columns=['eval', 'h', 'b', 'N', 'tau.us', 'tau.bc', 'se.us', 'se.rb']\n",
    "            ).to_csv('python_lprobust_results.csv', index=False)\n",
    "\n",
    "pd.DataFrame(bw_mse.bws, \n",
    "             columns=['eval', 'h', 'b']\n",
    "            ).to_csv('python_lpbwselect_results.csv', index=False)\n",
    "\n",
    "pd.DataFrame(result_kd.Estimate, \n",
    "             columns=['eval', 'h', 'b', 'N', 'f.us', 'f.bc', 'se.us', 'se.rb']\n",
    "            ).to_csv('python_kdrobust_results.csv', index=False)\n",
    "\n",
    "pd.DataFrame(bw_kd.bws, \n",
    "             columns=['eval', 'h', 'b']\n",
    "            ).to_csv('python_kdbwselect_results.csv', index=False)\n",
    "\n",
    "print(\"Results saved to:\")\n",
    "print(\"  - python_lprobust_results.csv\")\n",
    "print(\"  - python_lpbwselect_results.csv\")\n",
    "print(\"  - python_kdrobust_results.csv\")\n",
    "print(\"  - python_kdbwselect_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instructions for R Comparison\n",
    "\n",
    "Now run the companion R script `comparison_test.R` which performs the same tests.\n",
    "\n",
    "```r\n",
    "source(\"comparison_test.R\")\n",
    "```\n",
    "\n",
    "The R script will produce similar output that you can compare directly with the Python results above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
